{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c1cca82f",
   "metadata": {},
   "source": [
    "###  Model Building and Training\n",
    "1. Data Preparation\n",
    "2. Build Baseline Model\n",
    "3. Build Ensemble Model\n",
    "4. Cross-Validation (recommended)\n",
    "5. Model Comparison and Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2facae4e",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d6f642f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "\n",
    "\n",
    "from src.modeling import ModelTrainer\n",
    "model_trainer = ModelTrainer()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3307ffcd",
   "metadata": {},
   "source": [
    "## Load X and y data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6eda2e01",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(numpy.ndarray, numpy.ndarray)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = np.load('../Data/processed/x_fraud.npy', allow_pickle=True)\n",
    "y = np.load('../Data/processed/y_fraud.npy', allow_pickle=True)\n",
    "type(X), type(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47886ff4",
   "metadata": {},
   "source": [
    "## Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "47e95ae2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# STRATIFIED TRAIN-TEST SPLIT\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y,random_state=42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afe5a700",
   "metadata": {},
   "source": [
    "##  Baseline Model: Logistic Regression\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4bfd8da1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-score: 0.28203246064758175\n",
      "AUC-PR: 0.4076205226162818\n",
      "Confusion Matrix:\n",
      " [[15298  8078]\n",
      " [  725  1729]]\n"
     ]
    }
   ],
   "source": [
    "lr = LogisticRegression(solver='saga',max_iter=3000,class_weight=\"balanced\", random_state=42, n_jobs=-1)\n",
    "lr = model_trainer.train_model(lr, X_train, y_train) # Train model\n",
    "y_pred_lr, y_proba_lr = model_trainer.predict(lr, X_test) # Predictions\n",
    "metrics_lr = model_trainer.evaluate_model(y_test, y_pred_lr, y_proba_lr) # Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c048750",
   "metadata": {},
   "source": [
    "## Build Ensemble Model: Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7012399b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "rf = RandomForestClassifier(random_state=42,\n",
    "                            min_samples_split=5,\n",
    "                            class_weight=\"balanced\", n_jobs=-1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb1b8437",
   "metadata": {},
   "source": [
    "## Hyperparameter tuning (CV inside)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "933cd4f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n",
      "Best Parameters: {'n_estimators': 200, 'min_samples_split': 10, 'max_depth': 10}\n",
      "Best CV F1: 0.6380676962296854\n"
     ]
    }
   ],
   "source": [
    "param_dist = {\n",
    "    \"n_estimators\": [100, 200, 300],\n",
    "    \"max_depth\": [None, 5, 10],\n",
    "    \"min_samples_split\": [2, 5, 10],\n",
    "}\n",
    "\n",
    "tuning_results = model_trainer.hyperparameter_tuning(\n",
    "    model=rf,\n",
    "    param_distribution=param_dist,\n",
    "    x_train=X_train,\n",
    "    y_train=y_train\n",
    ")\n",
    "\n",
    "best_rf = tuning_results[\"best_model\"]\n",
    "print(\"Best Parameters:\", tuning_results[\"best_params\"])\n",
    "print(\"Best CV F1:\", tuning_results[\"best_score\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6144685",
   "metadata": {},
   "source": [
    "## Train Final Model on Full Training Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0de220b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_rf = model_trainer.train_model(best_rf, X_train, y_train) # Train model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec4c16a9",
   "metadata": {},
   "source": [
    "## Evaluate ONCE on Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b943fa5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-score: 0.70566534914361\n",
      "AUC-PR: 0.6377535403109238\n",
      "Confusion Matrix:\n",
      " [[23374     2]\n",
      " [ 1115  1339]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "y_pred_rf, y_proba_rf = model_trainer.predict(best_rf, X_test) # Predictions\n",
    "metrics_rf = model_trainer.evaluate_model(y_test, y_pred_rf, y_proba_rf) # Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9aefd5c2",
   "metadata": {},
   "source": [
    "### STRATIFIED K-FOLD CROSS-VALIDATION (k=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a3372afa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Logistic Regression CV: {'f1_mean': np.float64(0.2797920849514594), 'f1_std': np.float64(0.0008405338231541914), 'auc_pr_mean': np.float64(0.40066866976589066), 'auc_pr_std': np.float64(0.011656365637349037)}\n",
      "Random Forest CV: {'f1_mean': np.float64(0.7016739751687948), 'f1_std': np.float64(0.003584919463279463), 'auc_pr_mean': np.float64(0.6354803467072089), 'auc_pr_std': np.float64(0.0027828078083432864)}\n"
     ]
    }
   ],
   "source": [
    "_, lr_cv_results = model_trainer.cross_validation(lr, X_train, y_train)\n",
    "_, rf_cv_results = model_trainer.cross_validation(best_rf, X_train, y_train)\n",
    "\n",
    "print(\"\\nLogistic Regression CV:\", lr_cv_results)\n",
    "print(\"Random Forest CV:\", rf_cv_results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c4fa727a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 Model F1 Score (mean ± std) AUC-PR (mean ± std)\n",
      "0  Logistic Regression       0.2798 ± 0.0008     0.4007 ± 0.0117\n",
      "1        Random Forest       0.7017 ± 0.0036     0.6355 ± 0.0028\n"
     ]
    }
   ],
   "source": [
    "cv_results = {\n",
    "    'Model':['Logistic Regression', 'Random Forest'],\n",
    "    'F1 Score (mean ± std)':[\n",
    "        f\"{lr_cv_results['f1_mean']:.4f} ± {lr_cv_results['f1_std']:.4f}\",\n",
    "        f\"{rf_cv_results['f1_mean']:.4f} ± {rf_cv_results['f1_std']:.4f}\",\n",
    "    ],\n",
    "    'AUC-PR (mean ± std)':[\n",
    "        f\"{lr_cv_results['auc_pr_mean']:.4f} ± {lr_cv_results['auc_pr_std']:.4f}\",\n",
    "        f\"{rf_cv_results['auc_pr_mean']:.4f} ± {rf_cv_results['auc_pr_std']:.4f}\"\n",
    "    ]\n",
    "}\n",
    "comparison_df = pd.DataFrame(cv_results)\n",
    "print(comparison_df) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6b9f6841",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recommended model based on CV F1-score: Random Forest\n"
     ]
    }
   ],
   "source": [
    "recommended_model = \"Random Forest\" if rf_cv_results['f1_mean'] > lr_cv_results['f1_mean'] else \"Logistic Regression\"\n",
    "print(f\"Recommended model based on CV F1-score: {recommended_model}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dde2000",
   "metadata": {},
   "source": [
    "## Save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75155a11",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "joblib.dump(best_rf, \"../models/fraud_model.joblib\")\n",
    "\n",
    "np.save('../Data/processed/x_fraud_test.npy', X_test)\n",
    "np.save('../Data/processed/x_fraud_train.npy', X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "164b1576",
   "metadata": {},
   "source": [
    "# Model Comparison and Recommendation\n",
    "\n",
    "## Logistic Regression\n",
    "\n",
    "Baseline, interpretable model.\n",
    "\n",
    "F1-score is low (0.28) and AUC-PR is moderate (0.40).\n",
    "\n",
    "Shows that a linear model struggles to capture non-linear fraud patterns.\n",
    "\n",
    "## Random Forest\n",
    "\n",
    "Ensemble model that captures non-linear relationships.\n",
    "\n",
    "F1-score is high (0.70) and AUC-PR is significantly better (0.64).\n",
    "\n",
    "Standard deviation across folds is very low, indicating stable performance.\n",
    "\n",
    "## Recommendation:\n",
    "\n",
    "Random Forest is selected as the final model.\n",
    "\n",
    "Reason: It achieves higher predictive performance while maintaining stable cross-validated results, making it more suitable for detecting fraudulent transactions.\n",
    "\n",
    "Logistic Regression can still serve as a baseline or interpretable reference, but Random Forest is clearly superior for this imbalanced dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e1b486c",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
